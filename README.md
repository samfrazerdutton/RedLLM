# ğŸ”´ RedLLM â€” Offline Pentest Assistant

**RedLLM** is a beginner-friendly, offline **penetration testing assistant** powered by [Ollama](https://ollama.com).  
It helps students, exam takers, and professionals **learn and simulate security workflows** using local LLMs â€” safely and without an internet connection.

---

## ğŸ§  Why RedLLM?

Traditional AI tools require cloud connections and risk leaking data.  
RedLLM runs **completely offline**, using local LLMs (like Llama 3) via Ollama.  
It acts as a teaching partner â€” explaining pentest steps, suggesting commands, and logging results.

---

## âœ¨ Features

-  **Offline Operation** â€” no external API calls, no data leakage.  
-  **Teaching Mode** â€” beginner guidance for each tool and technique.  
-  **Session Logging** â€” keeps track of your pentest sessions for review.  
-  **Secure by Default** â€” `.env` ignored, secrets never exposed.  
-  **Model-Agnostic** â€” works with any Ollama-compatible LLM (e.g. Llama 3, Mistral, Phi 3).  

---

## Installation

### 1ï¸âƒ£ Clone the Repository
```bash
git clone git@github.com:samfrazerdutton/RedLLM.git
cd RedLLM
# in RedLLM directory
python3 -m venv .venv
source .venv/bin/activate

# install dependencies
pip install --upgrade pip
pip install -r requirements.txt
